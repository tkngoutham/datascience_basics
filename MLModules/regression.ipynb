{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on test set is 0.8712\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/tips.csv\")\n",
    "\n",
    "X = dataset[[\"total_bill\"]]\n",
    "y = dataset[[\"tip\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.7)\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"The MSE on test set is {0:.4f}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on test set is 2.1533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kittu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X = dataset[[\"total_bill\"]]\n",
    "y = dataset[[\"tip\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.7)\n",
    "\n",
    "reg = linear_model.SGDRegressor(loss='squared_error', max_iter=1000)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"The MSE on test set is {0:.4f}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on test set is 0.8712\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Ridge Regression L2 Regularization\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/tips.csv\")\n",
    "\n",
    "X = dataset[[\"total_bill\"]]\n",
    "y = dataset[[\"tip\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.7)\n",
    "\n",
    "reg = linear_model.Ridge(alpha=0.9)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"The MSE on test set is {0:.4f}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on test set is 0.8730\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Lasso Regression L1 Regularization\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/tips.csv\")\n",
    "\n",
    "X = dataset[[\"total_bill\"]]\n",
    "y = dataset[[\"tip\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.7)\n",
    "\n",
    "reg = linear_model.Lasso(alpha=0.1)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"The MSE on test set is {0:.4f}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on test set is 0.8833\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Elastic Net Regression\n",
    "\n",
    "Elastic-Net Regression incorporates both L1-Regularization and L2-Regularization while building the Linear Regression Model. This allows us\n",
    "\n",
    "Learn a sparse model where few of the weights or parameters are non-zero like Lasso (L1-Regularization).\n",
    "\n",
    "Maintain the properties of Ridge Regression (L2-Regularization).\n",
    "\n",
    "l1_ratio is the ElasticNet mixing parameter with a value between 0 and 1.\n",
    "\n",
    "For l1_ratio = 0, L2-Regularization is used.\n",
    "\n",
    "For l1_ratio = 1, L1-Regularization is used.\n",
    "\n",
    "For 0 < l1_ratio < 1, the combination of both L1 and L2 are used.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/tips.csv\")\n",
    "\n",
    "X = dataset[[\"total_bill\"]]\n",
    "y = dataset[[\"tip\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.7)\n",
    "\n",
    "reg = linear_model.ElasticNet(l1_ratio=0.5)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"The MSE on test set is {0:.4f}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on test set is 1.0160   for kernal rbf\n",
      "The MSE on test set is 0.9205   for kernal linear\n",
      "The MSE on test set is 18.3361   for kernal sigmoid\n",
      "The MSE on test set is 1.2018   for kernal poly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kittu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kittu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kittu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kittu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "'''Support Vector Regression\n",
    "The idea of Support Vector Regression has been borrowed from Support Vector Machines. In classification, we predict a discrete-valued output. Here are some things to note:\n",
    "\n",
    "As the name suggests Support Vector Regression is used for predicting the real-valued output.\n",
    "\n",
    "The model produced by Support Vector Regression depends only on a subset of the training data.\n",
    "\n",
    "There is a concept of Kernel, which involves mapping the features or columns or dimensions to higher dimensions to make the problem solvable.'''\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/tips.csv\")\n",
    "\n",
    "X = dataset[[\"total_bill\"]]\n",
    "y = dataset[[\"tip\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.7)\n",
    "\n",
    "for k in ['rbf', 'linear', 'sigmoid', 'poly']:\n",
    "    reg =  SVR(kernel=k)\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    print(\"The MSE on test set is {0:.4f}  \".format(mean_squared_error(y_test, y_pred))+\" for kernal \"+str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on test set is 1.1852 num nearest neighbours 2\n",
      "The MSE on test set is 1.0105 num nearest neighbours 3\n",
      "The MSE on test set is 1.0105 num nearest neighbours 4\n",
      "The MSE on test set is 0.9872 num nearest neighbours 5\n",
      "The MSE on test set is 0.9542 num nearest neighbours 6\n",
      "The MSE on test set is 1.0054 num nearest neighbours 7\n",
      "The MSE on test set is 1.0365 num nearest neighbours 8\n",
      "The MSE on test set is 0.9841 num nearest neighbours 9\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Nearest Neighbors Regression\n",
    "The idea of Nearest Neighbor Regression has been borrowed from Nearest Neighbors Classification. Note that:\n",
    "\n",
    "The principle behind the nearest neighbors algorithm in regression is to find the nearest, letâ€™s say, k neighbors. The neighbors are calculated based on some measure of similarity or distance calculation. Based on the value K chosen and neighbors retrieved, this algorithm is also called K-Nearest neighbors.\n",
    "\n",
    "K\n",
    "K\n",
    " is a parameter that can be tuned.\n",
    "\n",
    "The output value for a new instance is returned by taking the mean of its nearest neighbors in case of Regression. The important thing to remember is that no equation is constructed and no parameters are optimized.\n",
    "\n",
    "The nearest neighbors algorithms remembers all the training dataset and comes under the category of non-generalizing algorithms of Machine Learning. It stores the training dataset in some efficient data structure.\n",
    "\n",
    "Implementation in Scikit Learn\n",
    "The KNeighborsRegressor class implements the KNN algorithm.\n",
    "'''\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/tips.csv\")\n",
    "\n",
    "X = dataset[[\"total_bill\"]]\n",
    "y = dataset[[\"tip\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.7)\n",
    "\n",
    "\n",
    "for i in range(2,10):\n",
    "    reg =  KNeighborsRegressor(n_neighbors=i)\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    print(\"The MSE on test set is {0:.4f}\".format(mean_squared_error(y_test, y_pred))+\" num nearest neighbours \"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on test set is 2.3152\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The idea of the Decision Tree Regression has been borrowed from Decision Tree Classification. Note that:\n",
    "\n",
    "Decision Trees create a tree structure from the dataset at hand. It learns the if/else structure from the dataset.\n",
    "\n",
    "We will look into the key algorithms to make a Decision Tree in the Classification section. In the case of Regression, it just returns the continuous valued output for an instance.\n",
    "'''\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/tips.csv\")\n",
    "\n",
    "X = dataset[[\"total_bill\"]]\n",
    "y = dataset[[\"tip\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.7)\n",
    "\n",
    "reg =  tree.DecisionTreeRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"The MSE on test set is {0:.4f}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Some advanced Regression algorithms are mentioned below.\n",
    "\n",
    "Least Angle Regression (LARS)\n",
    "Polynomial Regression\n",
    "Bayesian Regression\n",
    "Robustness Regression\n",
    "Isotonic Regression\n",
    "\n",
    "\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0d9a2c96556070c053a5505449737c0c917f0999d5c0130a66505f5d6505202"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
